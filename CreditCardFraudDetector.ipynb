{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYTOYWrxtrR5NhOtP3chEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamyaKGokul/Python-DL-Projects/blob/main/CreditCardFraudDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up and Data Loading\n"
      ],
      "metadata": {
        "id": "8V4HNEXRju8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erA__PCocBa-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import average_precision_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(\"Time\", axis=1, inplace=True)\n",
        "sns.countplot(data[\"Class\"])\n"
      ],
      "metadata": {
        "id": "GhAY6zw-cLaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().any().describe()"
      ],
      "metadata": {
        "id": "PGfA-N9QcPt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limit = int(0.9*len(data))\n",
        "train = data.loc[:limit]\n",
        "val_test = data.loc[limit:]\n",
        "val_test.reset_index(drop=True, inplace=True)\n",
        "val_test_limit = int(0.5*len(val_test))\n",
        "val = val_test.loc[:val_test_limit]\n",
        "test = val_test.loc[val_test_limit:]"
      ],
      "metadata": {
        "id": "n9stHTUXcSSo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of fraudulent transactions in the validation set: {}\"\\\n",
        "      .format(val[\"Class\"].value_counts()[1]))\n",
        "print(\"Number of fraudulent transactions in the test set: {}\"\\\n",
        "      .format(test[\"Class\"].value_counts()[1]))"
      ],
      "metadata": {
        "id": "-dPnEoWhcUy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting training and test datasets"
      ],
      "metadata": {
        "id": "joeSBkZNj28M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_positive = train[train[\"Class\"] == 1]\n",
        "print(train_positive)\n",
        "train_positive = pd.concat([train_positive] * int(len(train) / len(train_positive)), ignore_index=True)\n",
        "noise = np.random.uniform(0.9, 1.1, train_positive.shape)\n",
        "train_positive = train_positive.multiply(noise)\n",
        "train_positive[\"Class\"] = 1\n",
        "train_extended = train.append(train_positive, ignore_index=True)\n",
        "train_shuffled = train_extended.sample(frac=1, random_state=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "TgQ5Xt8IcW5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the balanced data"
      ],
      "metadata": {
        "id": "AlXsYjT_j8Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(train_shuffled[\"Class\"])"
      ],
      "metadata": {
        "id": "vjN1n5HdcY6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_shuffled.drop(labels=[\"Class\"], axis=1)\n",
        "Y_train = train_shuffled[\"Class\"]\n",
        "X_val = val.drop(labels=[\"Class\"], axis=1)\n",
        "Y_val = val[\"Class\"]\n",
        "X_test = test.drop(labels=[\"Class\"], axis=1)\n",
        "Y_test = test[\"Class\"]"
      ],
      "metadata": {
        "id": "-sq8RENzcawC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the train and test datasets"
      ],
      "metadata": {
        "id": "hHJYKzPLkL3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
        "X_val[X_val.columns] = scaler.transform(X_val)\n",
        "X_test[X_test.columns] = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "h3lGLg2Pcca9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building and training the model"
      ],
      "metadata": {
        "id": "taI60pYwkaEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(4, activation=\"relu\"))\n",
        "model.add(Dense(2, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "history = model.fit(X_train, \n",
        "                    Y_train, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_val, Y_val), \n",
        "                    callbacks=[ReduceLROnPlateau(patience=3, verbose=1, min_lr=1e-6), \n",
        "                               EarlyStopping(patience=5, verbose=1)])"
      ],
      "metadata": {
        "id": "cOnNPVkdces2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the accuracy and loss of the model"
      ],
      "metadata": {
        "id": "f98u2Y30klXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = len(history.history[\"loss\"])\n",
        "fig, axarr = plt.subplots(1, 2, figsize=(24, 8))\n",
        "axarr[0].set_xlabel(\"Number of Epochs\")\n",
        "axarr[0].set_ylabel(\"Loss\")\n",
        "sns.lineplot(x=range(1, num_epochs+1), y=history.history[\"loss\"], label=\"Train\", ax=axarr[0])\n",
        "sns.lineplot(x=range(1, num_epochs+1), y=history.history[\"val_loss\"], label=\"Validation\", ax=axarr[0])\n",
        "axarr[1].set_xlabel(\"Number of Epochs\")\n",
        "axarr[1].set_ylabel(\"Accuracy\")\n",
        "axarr[1].set_ylim(0, 1)\n",
        "sns.lineplot(x=range(1, num_epochs+1), y=history.history[\"accuracy\"], label=\"Train\", ax=axarr[1])\n",
        "sns.lineplot(x=range(1, num_epochs+1), y=history.history[\"val_accuracy\"], label=\"Validation\", ax=axarr[1])"
      ],
      "metadata": {
        "id": "0xKWOHPjchUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "sgioOrZZkxny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = model.evaluate(X_test, Y_test)\n",
        "print(\"The model test accuracy is {}.\".format(test_results[1]))"
      ],
      "metadata": {
        "id": "yjs0aWqTcjLI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}